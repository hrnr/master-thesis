\chapter{Merging algorithm}
\label{chap:mergingalgorithm}

% TODO add visualisation

\begin{algorithm}
    \caption[Pair-wise transformation estimation]{Estimates pair-wise transformation between two points-clouds}
    \label{alg:estimate-pair}
    \begin{algorithmic}[1]
        \Require $2$ maps represented as pointclouds
        \Ensure transformation estimate between $2$ maps
        \Procedure{estimateTransform}{$map1, map2$}
            \State down-sample to working resolution
            \State remove outliers
            \State detect keypoints
            \State detect normals
            \State compute descriptor for each keypoint
            \State match descriptors and compute initial transformation
            \State refine transformation with \gls{ICP}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

This section presents an algorithm for estimating transformations between $n$ pointclouds and merging them together. As discussed in the chapter~\ref{chap:analysis}, we work with maps represented as pointclouds, possibly with RGB information for each point.

There are two core problems for estimating the transformation. First we need to able to estimate pair-wise transformation for $2$ maps using only geometrical and possibly colour information available within pointclouds. We discuss our method in section~\ref{sec:estimate-pair-wise}. Second, we want to get a transformation for each of the maps to the selected reference frame. This is discussed in section~\ref{sec:estimate-global}.

After we have estimated the transformations we can stitch them to create the global map.

\section{Estimating pair-wise transformation}
\label{sec:estimate-pair-wise}

Algorithm~\ref{alg:estimate-pair} describes a pipeline of pointcloud algorithms to estimate the pair-wise transformation. Every step is discussed in the following sections.

\subsection{Down-sampling}

As we are working with possibly large-scale maps, input pointclouds may contain millions of points. To reduce computation times it is highly desirable to reduce number of points. As discussed in section~\ref{chap:analysis}, in multi-robot system this step is typically performed by \gls{SLAM} running on each robot before publishing the map, thus saving bandwidth of the communication. However for the purpose of transformation estimation, we might want reduce resolution even further to reduce computation time (for example each robot might publish a map with typical resolution $0.05 m/\text{voxel}$, but for estimation we might work with resolution $0.1 m/\text{voxel}$).

We show is the section~\ref{chap:evaluation} that our algorithm can reliable estimate the transformation in just $0.1 m/\text{voxel}$ resolution.

Common technique for reducing resolution of pointcloud is voxelisation, which produces a voxel grid. The voxel grid is a regularly spaced, three-dimensional grid. We can represent the voxel grid as a normal pointcloud, with each point representing a voxel of the voxel grid. We don't usually save empty space information, so the grid is sparse.

Algorithm for voxelisation is simple. For each voxel (size of the voxel is determined by the resolution) we take all points contained in the voxel and approximate them with their centroid.

\subsection{Removing outliers}

Although the voxelisation can deal some some of the noise and inaccuracies, during experiments it has been beneficial to perform further outliers filtering to remove far laying outliers. Far-laying outliers may end-up being detected as keypoints, but they are usually not matched. Reducing the number of detected keypoints speeds up the later phases of estimation.

I have selected to use a simple radius-based outlier removal. This method searches for neighbour of each point with certain radius and removes points that have neighbours count below certain threshold.

Because the radius outlier removal removes only the points with few close neighbours, it does not reduce the robustness of the estimation. Because descriptors of the outlier points are based on just a few points, they didn't produced a robust matching candidates during experiments.

For example on $2$ maps from \gls{AAU} dataset (see section~\ref{sec:aau-dataset}), outlier removal removes $326$ and $271$ points respectively ($7.29\%$, $6.16\%$), but number of detected keypoints decreases from $66, 63$ to $51, 56$ ($22.73\%$, $11.11\%$). Outlier removal didn't impact the estimation process negatively.

\subsection{Estimating surface normals}

The last preprocessing step is to estimate surface normals. Surface normals are used in later steps to compute descriptors and by Harris keypoint detector.

Algorithm for estimating surface normals is described in~\cite{RusuDoctoralDissertation}. The most important parameter for normals estimation is the size of the neighbourhood which is used for the estimation. This can be configured by the user.

\subsection{Detecting keypoints}

Even after the down-sampling the maps contain usually too many points to work with all of them in later steps. We need to reduce the number of points further. Common technique used in the area of computer vision and robotics is to search for keypoints that identify suitable points for later matching.

There are two families of keypoints detectors that are being used with pointclouds. Most of the approaches has been adapted from keypoints detectors that has been originally developed to work on images.

First class of detectors uses RGB colour information stored for each point in the pointcloud. This approach suppose that the pointcloud has been obtained with detector that provide the colour information such as stereo rig camera setup, active RGB-D cameras etc. For our approach we use \gls{SIFT} keypoint detector, which is an adapted algorithm from~\cite{lowe2004distinctive} that works on pointclouds with RGB information.

Second class of algorithms works with just geometrical information and is therefore able to work with pointclouds that do not store any additional information for points. These algorithms can be used with pointclouds composed of laser scans. Our algorithm implements Harris 3D keypoint detector for this purpose, which is an adapted algorithm from~\cite{harris1988combined}. Instead of using image gradients, which are not available in the pointcloud without colour information, it uses surface normals, that capture geometrical properties of the point neighbourhood.

\subsection{Computing descriptors}

Next step is computing a local descriptor around each detected keypoint to be able to match keypoints between maps. Unlike the keypoint detection algorithms, algorithms for computing descriptors has been mostly designed from scratch to work on pointclouds. Comprehensive review of the descriptors is given in~\cite{YasirThesis}.

Most of the descriptors does not use the colour information and uses only local geometry around the point. Widely used \gls{PFH} descriptors~\cite{rusu2008pfh} use a multi-dimensional histogram with $125$ bins to provide an informative signature of a point neighbourhood. The histogram captures relationships between estimated surface normals (from previous step). It uses relationships between all pairs of points in the neighbourhood and therefore has complexity $\bigO(k^2)$, where $k$ is number of points in the neighbourhood. There is a variant of \gls{PFH} descriptors \gls{PFHRGB} that stores also colour information in the extended histogram of $2 \times 125$ bins.

Main disadvantage of the \gls{PFH} descriptors is the high algorithmic complexity and therefore the slow processing speed~\cite{rusu2009fpfh}. We support also \gls{FPFH}~\cite{rusu2009fpfh}, \gls{SHOT} with colour~\cite{tombari2011shot}, \gls{RSD}~\cite{marton2010rsd} and \gls{SC3D}~\cite{frome2004sc3d} novel descriptors which offer better processing speed compared to \gls{PFHRGB} and \gls{PFH}.

\subsection{Matching descriptors}
\label{sec:matching}

Next step in the pipeline is the descriptors matching, which will yield a transformation estimate. I uses the features extracted from pointclouds in the previous steps.

We match two sets of descriptors from two pointclouds. For each descriptors from the first set we want to find a descriptor in the second set, which describe the same place (in the second pointcloud). This step is challenging, because the descriptors might be less descriptive than optimal. Therefore the correct match might not be always the closest descriptor, but the $k$-nearest descriptor.

To overcome the issue \gls{SAC-IA} algorithm~\ref{alg:sac-ia} has been proposed in~\cite{rusu2009fpfh}.

\begin{algorithm}
    \caption[\gls{SAC-IA}]{\gls{SAC-IA} algorithm from~\cite{rusu2009fpfh}.}
    \label{alg:sac-ia}
    \begin{algorithmic}[1]
        \Require $D_1, D_2$ set of descriptors
        \Ensure rigid transformation estimate
        \Function{\gls{SAC-IA}}{$D_1, D_2$}
            \Loop repeat $N$ times
                \State $K \gets$ draw $n$ descriptors from $D_1$
                \ForAll{$d_i \in K$}
                    \State $M \gets k$-nearest matches from $D_2$
                    \State $m_i \gets$ random sample from $M$
                \EndFor
                \State estimate rigid transformation for selected samples
                \State determine inliers
            \EndLoop
            \State \Return transformation with the most inliers.
        \EndFunction
    \end{algorithmic}
\end{algorithm}

The algorithm combines random matching of $k$-nearest descriptors and \gls{RANSAC}~\cite{fischler1981ransac}.

The algorithm was originally developed to work with \gls{FPFH} descriptors, that are fast to compute, but less descriptive that \gls{PFH}. With \gls{PFH} and \gls{PFHRGB} descriptors \gls{SAC-IA} sometimes yields sub-optimal transformation, even when there are good potential matches available in the descriptors sets. This let us to development a new matching algorithm~\ref{alg:cross-match}. The new matching algorithm is deterministic to avoid problems caused by the use of randomness in \gls{SAC-IA}.

The algorithm is based on the idea of reciprocal match validation. When we are considering match $d_i \rightarrow d_j$, we try to match also $d_j \rightarrow d_i$. We consider all $k$-nearest neighbours for matching to deal with potential low descriptiveness and then select the best match with reciprocal match validation. We do not include \gls{RANSAC} in the scheme, output of our algorithm are just matched pairs of descriptors.

\begin{algorithm}
    \caption[Reciprocal $k$-nearest matching]{Our matching approach using $k$-nearest matches validated with reciprocal matching}
    \label{alg:cross-match}
    \begin{algorithmic}[1]
        \Require $D_1, D_2$ set of descriptors
        \Ensure set of matches between $D_1, D_2$
        \Function{matchReciprocalK}{$D_1, D_2$}
            \State $M = \{\}$
            \ForAll{$d_i \in D_1$}
                \State $N \gets k$-nearest neighbours of $d_i$ in $D_2$
                \ForAll{$d_j \in N$}
                    \State $N' \gets k$-nearest neighbours of $d_j$ in $D_1$
                    \If{$d_i \in N'$}
                        \State $M \gets M \cup \{(d_i, d_j)\}$
                    \EndIf
                \EndFor
            \EndFor
            \State \Return $M$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Notice that our algorithm does not need any threshold for the maximum match distance and can therefore work with various kinds of descriptors without any need for a specific configuration. The only parameter is $k$ -- number of neighbours. As discussed in section~\ref{chap:evaluation} our approach shows better performance when there are enough good possible matches and is not influenced by randomness.

Both \gls{SAC-IA} and our reciprocal matching algorithm need to quickly find $k$-nearest neighbours. To achieve a good performance we use a approximative nearest neighbour search based on~\cite{muja2014flann}. This solution allows us to match large number of descriptors quickly, even though computational complexity rises significantly with $k$. During our experiments the matching step takes usually just a fraction of time needed to extract keypoints and descriptors.

\section{Estimating the final transformation}

\gls{SAC-IA} embeds \gls{RANSAC} into its algorithm and therefore provides directly an initial transformation estimate. When we use our matching scheme as per algorithm~\ref{alg:cross-match}, we need to run \gls{RANSAC} step with rigid transformation model after the matching to get inliers matches. In the typical scenario most of the matches will be outliers, so without the \gls{RANSAC} step it would not be possible to estimate a consistent transformation.

\gls{RANSAC} transformation estimate is always based on the minimum number of points required to estimate the model (rigid transformation). To get better estimate for all inliers pairs we recompute the transformation estimate using least-squares on inlier pairs. We use \gls{SVD} to compute the new estimate, the technique is described in~\cite{golub1970svd}. Another widely used technique in Computer Vision is to use a non-linear least squares approach, such as Levenberg-Marquardt algorithm described in~\cite{more1978levmarq}, to optimize the transformation estimate re-projection error considering all inliers. Because we refine the transformation further with \gls{ICP}, there hasn't been any observed difference between using Levenberg-Marquardt or \gls{SVD}-based technique. Our implementation uses \gls{SVD} to refine the transformation on inliers.

So far we have used only detected keypoints and descriptors computed around the keypoints to estimate the transformation. To refine the transformation using all points in the pointcloud we use \gls{ICP} algorithm introduced in~\cite{besl1992icp}. \gls{ICP} algorithm tries to minimize euclidean error distance between estimated corresponding points. The estimated transformation from either \gls{SAC-IA} or our matching scheme presented in section~\ref{sec:matching} is used as an initial guess for \gls{ICP}.

The initial guess is usually close to the final transformation estimated by \gls{ICP}, especially when using our algorithm~\ref{alg:cross-match} and \gls{RANSAC} for estimation. Even though we use possibly many points with \gls{ICP}, because of the proximity of the guess to the final transformation only a couple of iterations is needed for \gls{ICP} to converge, so the refinement does not impact overall performance significantly.

Since the introduction of \gls{ICP} many \gls{ICP}-derived algorithms have been introduced to overcome issues associated with \gls{ICP}, especially to avoid local minima. A comprehensive review is given in~\cite{pomerleau2015reviewregistration}. Because our initial transformation is usually very close to the final transformation, the original \gls{ICP} algorithm performed well for our usecase during experiments.

\gls{ICP} refinement is the last step in estimating pairwise transformation. We use the output of the \gls{ICP} as the final estimated transformation between two maps.

\section{Estimating global transformations}
\label{sec:estimate-global}
