\chapter{Analysis}
\label{chap:analysis}

Knowledge of the positions of robots and knowledge of the environment is essential for solving complex tasks efficiently in multi-robot systems. Over time various techniques evolved to acquire this knowledge.

\section{Map-merging}

This work focuses on multi-robot systems consisting of mobile robots, each capable of building a \gls{3D} map of the surrounding environment. Typically each robot uses a \gls{SLAM} algorithm to create a map and is equipped with appropriate sensors such as stereo camera rigs, active \gls{RGB-D} cameras or laser rangefinders. Such sensors are available in the broad weight and cost range enabling a large variety of \gls{SLAM}-capable robots operating both on the ground and in the air. This variety leads to possible heterogeneous teams of robots capable of solving a broad range of tasks.

The \textit{map-merging problem} for multi-robot systems, which is the focus of this work, is to estimate positions of the robots in the environment and to merge the maps from individual robots to produce a single globally consistent map.

\section{The map representation}

\Gls{3D} maps are becoming more common in the robotics as the capable sensors are getting more affordable and suitable for many applications. Unlike \gls{2D} occupancy grids used extensively in the past, \gls{3D} maps enable cooperation of robots, that are not fixed to a \gls{2D} plane, such as aerial vehicles, humanoid robots, outdoor robots operating in a rough terrain as well as traditional ground-based platforms. This allows us to create possibly heterogeneous multi-robot teams, that are able to take advantage of their different strengths and weaknesses to solve the assigned task efficiently. For example, a robotic team can consist of aerial vehicles, capable of fast reconnaissance in large-scale outdoor environments, and ground-based vehicles carrying heavy equipment.

This work expects maps represented as point clouds (Definition~\ref{def:point-cloud}). Point clouds can be implemented as an array of points, making them suitable for serialisation and exchange between robots. Points in the point cloud can have assigned additional information, such as \gls{RGB} colour information or reflection intensity, based on the available sensor. Especially colour information, that is provided by stereo camera rigs and active \gls{RGB-D} cameras is commonly exploited for further processing (Figure~\ref{fig:v1-greyscale}).

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{../img/v1-greyscale.png}
    \caption[Point cloud map with greyscale colours]{Partial point cloud map of a room created from the aerial vehicle equipped with greyscale stereo cameras rig. Intensity captured by the camera is stored alongside the points and visualised in greyscale. The map was created from The EuRoC micro aerial vehicle dataset ``Vicon Room 1 02'' (Section~\ref{sec:euroc-dataset}).}
    \label{fig:v1-greyscale}
\end{figure}

\begin{defn}[Point cloud]
\label{def:point-cloud}
A point cloud is a set of data points in space.
\end{defn}

Other data structures used in the \gls{3D} mapping, such as octree-based maps used by~\citet{hornung2013octomap}, can be converted to point clouds without any loss of information because point clouds do not pose any restrictions on the geometry of the points and it is easy to add metadata associated with the points. This makes point clouds a suitable data structure for exchange between different mapping approaches, even when they use different representations internally.

Point clouds data messages are supported and well established in the \gls{ROS} framework. There are mature libraries to work with point clouds, such as \gls{PCL}. This makes point clouds suitable map representation for multi-robot systems.

\section{Related works}

The map-merging is often a core part of a multi-robot system and various approaches have been developed to solve the map-merging problem. Most of the listed techniques work with robots operating in the \gls{2D} space (ground-based robots), but some of those techniques may be adapted to work in the \gls{3D} space too. The robot rendezvous techniques (Section~\ref{sec:direct-map-merging}) and \textit{indirect map-merging} techniques (Section~\ref{sec:map-merging-grids}) have been used mostly with a \gls{2D} assumption, while distributed \gls{SLAM} techniques (Section~\ref{sec:map-merging-distributed-slam}) can be used also in the \gls{3D} case.

\subsection{Direct map-merging}
\label{sec:direct-map-merging}

Early map-merging techniques, classified as \textit{direct map-merging} by~\citet{lee2012survey}, use direct sensor measurements to compute the transformation between robots. This involves especially the case of robot rendezvous used by~\citet{zhou2006rendezvous}, which relies on robots' ability to sense each other position directly. Popular techniques use a camera and special recognizable markers on the robots to compute the transformation using computer vision algorithms.

A robot rendezvous might be hard to achieve in large-scale environments, especially if the robots are starting from different locations or in a different time (for example to react to increasing demands for the service). Such applications typically need map-merging to be able to work only with the sensed surrounding environment instead of the presence of other robots in the same space.

Direct map-merging also involves techniques relying on global localization in the environment being available. This involves purpose-adapted environments with installed markers or beacons to locate robots within environment and systems using global localization such as \gls{GPS}.

While purpose-adapted environments may greatly simplify the map-merging problem, they make deployment of the multi-robot systems harder and might introduce severe costs. For applications such as space exploration, disaster rescue, victim search and mine cleaning any modifications of the environment are not conceivable and in many more applications such as unmanned delivery, the modifications are usually not practical.

Global localization systems are usually not available indoor and while such systems are a great aid for navigating large-scale outdoor environments, the provided accuracy is usually not high enough for merging high-resolution point cloud maps. The position from global localization systems can be however used as an initial guess for map-merging algorithms.

\subsection{Map-merging on occupancy grids}
\label{sec:map-merging-grids}

Later developed techniques work with \gls{2D} maps, usually represented as occupancy grids. \citet{lee2012survey}~categorize these techniques as \textit{indirect map-merging}. These techniques rely on overlapping areas in maps for map-merging.

Using \gls{2D} maps limits operational space of robots and practically limits multi-robot teams to only ground-based vehicles operating indoor or in light terrain, flat environments. Particularly \gls{2D} maps prohibit promising multi-robot teams consisting of aerial and ground-based vehicles.

Map-merging techniques for \gls{2D} occupancy grids involves spectra-based approach of~\citet{carpin2008spectra} and my previous work based on image feature approach~\citep{Horner2016}.

My previous work is available in the \gls{ROS} distribution as a ready-made solution for merging \gls{2D} maps. It influenced the presented \gls{3D} map-merging algorithm as I have gathered feedback from the \gls{ROS} community. From experience, it is especially important to select a suitable interoperable map format in \gls{ROS}, so that the implementation can be used with existing \gls{SLAM} algorithms in \gls{ROS}. The idea of automatic robot discovery (Section~\ref{sec:configuration}) enabling convenient configuration and the idea of decoupling inter-robot communication platforms and the map-merging algorithm (Section~\ref{sec:communication}) are reused in the presented implementation (Chapter~\ref{chap:implementation}). However, the presented map-merging algorithm (Chapter~\ref{chap:mergingalgorithm}) has been designed from scratch and is based on different techniques as the data structures for \gls{2D} maps (occupancy grid) and \gls{3D} maps (point cloud) are different. The idea of converting occupancy grids to images and the idea of reusing image-based techniques, as used in my previous work, are not applicable.

\subsection{Map-merging as distributed SLAM}
\label{sec:map-merging-distributed-slam}

Map-merging algorithms have been also implemented as distributed \gls{SLAM} algorithms. These techniques take advantage of the research in the area of \gls{SLAM} algorithms and use loop-closure techniques developed for \gls{SLAM} to implement map-merging. Especially graph-based \gls{SLAM} implementations can be naturally extended to merge maps from multiple robots. Nodes from other robots can be added to the \gls{SLAM} graph and connected through loop-closures with existing nodes to form a single map.

When a loop-closure between 2 maps is detected, it can be used to compute the transformation between maps. We need to extend the loop detection to work across map boundaries, not only within a single map as usual in the \gls{SLAM}, which typically requires exchanging implementation-specific data between robots. This poses several disadvantages. Based on the \gls{SLAM} loop-closure approach the internal \gls{SLAM} data may be quite large (Table~\ref{tabl:rtabmap-db-vs-point-clouds}), stressing communication bandwidth. Exchanging implementation-specific data usually leads to running the same \gls{SLAM} algorithm on all robots in the multi-robot system, or the implementations must be adapted to exchange compatible loop-closure data. This is challenging for heterogeneous multi-robot systems when individual robots use different sensors, which is often the case when using both ground-based and aerial robots. For example, if ground-based robots are equipped with accurate heavy \gls{3D} laser range finder and aerial vehicles use lightweight stereo rig cameras, the \gls{SLAM} approaches are typically different and the loop-closure data are inherently incompatible (image features and \gls{3D} laser scans). In such scenarios, we need to use a different approach.

\citet{lee2012survey}~list scan matching loop closure approaches used for map-merging, which are used with \gls{2D} \gls{SLAM} algorithms. \gls{2D} distributed \gls{SLAM} based on scan matching was implemented by~\citet{pfingsthorn2007scalable} for the RoboCup Rescue Virtual Robots competition. \citet{fox2006distributed} used a direct exchange of laser range scans and odometry motion information coupled with a particle filter to localize a robot in the second map.

In \gls{3D} camera-based \gls{SLAM} algorithms, visual appearance-based techniques are particularly popular. \citet{tomono2013merging} used an appearance-based algorithm based on \gls{SIFT} features to merge visual maps, validated by travelled paths to reject false similarities in repetitive environments. Visual bag-of-words loop closure approach was used by~\citet{labbe2014online} to merge maps in multi-session \gls{SLAM}. Multi-session \gls{SLAM} works with maps generated by a single robot starting consecutively in the different positions. In such setup there is no need for communication, so a local database was used by the authors to store loop-closure related data for map-merging.

\section{Map-merging on point clouds}
\label{sec:map-merging-on-point-clouds}

The algorithm presented in Chapter~\ref{chap:mergingalgorithm} works exclusively with \gls{3D} point clouds without any additional exchange of data to offer maximum flexibility. The algorithm does not require any exchange of implementation-specific data and can be used with any \gls{SLAM} approach available, allowing future integration of the newest state-of-the-art methods in fast-paced \gls{SLAM} research. With the presented approach, each robot in the heterogeneous multi-robot system can use a different \gls{SLAM} implementation, which allows using best-suited implementation to robot sensors and computational capabilities.

Using point clouds can also save communication bandwidth especially compared to image-based loop closure methods, which may require to exchange a significant amount of data. Size comparison between local database size used in multi-session \gls{SLAM} by~\citet{labbe2014online}, implemented in popular \texttt{RTAB-Map} \gls{SLAM}, and point cloud representation of the same maps are shown in Table~\ref{tabl:rtabmap-db-vs-point-clouds}. The maps have been recorded at Charles University campus, see Section~\ref{sec:mff-dataset} for details. The point clouds are significantly smaller with the resolution of $0.05$ meters per voxel. The presented merging algorithm can work with the resolution of just $0.1$ meters per voxel in which point clouds are even smaller, so we could save more bandwidth if necessary.

\begin{table}[b!]

	\centering
	\begin{tabular}{lrr D{.}{.}{3}}
	\toprule
	\textbf{Map} & \textbf{Database} & \textbf{Point cloud} & \textbf{Ratio} \\
	\midrule
	mff-mapping\_2018-04-06-13-43-39 & 217 MiB & 14 MiB & 0.066 \\
	mff-mapping\_2018-04-12-10-17-25 & 551 MiB & 33 MiB & 0.060 \\
	mff-mapping\_2018-04-12-11-04-51 & 231 MiB & 11 MiB & 0.048 \\
	mff-mapping\_2018-04-12-13-30-41 & 350 MiB & 16 MiB & 0.046 \\
	\bottomrule
	\end{tabular}
	\caption{Table comparing sizes of the local database of loop closure data for map-merging used by~\citet{labbe2014online} and the point cloud representation of the same maps. Ratio denotes the fraction of the point cloud size to the database size. The maps are presented in Section~\ref{sec:mff-dataset}.}
	\label{tabl:rtabmap-db-vs-point-clouds}
\end{table}

Note that the local database has been used only in multi-session \gls{SLAM} and might not be size-optimised. Still, the table demonstrates the order of magnitude differences between the two representations.

There are some challenges for map-merging on point clouds. When using \gls{SLAM}-based approaches for map-merging, the resulting graph is usually optimized, which can repair mapping errors present in the individual maps. Repairing mapping errors in point clouds maps is much harder. \citet{bonanni2017pose} addressed this problem by using pose graphs of point clouds. In the pose graph representation, the map is represented as a graph of smaller point cloud sub-maps, not as one big point cloud. This representation allows repairing maps in the similar manner as done in distributed \gls{SLAM} approaches, by optimizing the graph after merging.

Another challenge is to register the point clouds (to compute the transformation between point clouds) using only information stored within point clouds. The algorithm implemented by~\citet{bonanni2017pose} relies on an external place recognition routine that reports matching pairs of local maps. The external routine is needed because authors used a pairwise registration algorithm, that needs an initialisation with a roughly-correct transformation to align point clouds. The algorithm presented in Chapter~\ref{chap:mergingalgorithm} can register point clouds directly using a global registration approach that does not need any external place recognition routine. To the best of my knowledge, this approach is the first map-merging method
that can work directly on \gls{3D} point clouds without any external pre-alignment routine.

Most of the methods for point cloud registration are based on the \gls{ICP} algorithm introduced by~\citet{besl1992icp}. The \gls{ICP} algorithm uses an initial transformation estimate and it iteratively tries to minimise error metric (usually a Euclidean distance between point clouds). The initialisation is extremely important as the algorithm always finds a local minimum. Since the introduction of the \gls{ICP} algorithm, variants, reviewed in~\citet{pomerleau2015reviewregistration}, of the original algorithm has been developed, which are less susceptible to an accurate initialisation, but all \gls{ICP}-derived algorithms need the initialisation and are susceptible to local minima problems.

When using \gls{ICP}-family algorithms for scan matching in the context of \gls{SLAM}, the initial estimate is usually provided by the odometry source. In the map-merging problem, the initial estimate must be provided from an external source, either manually by the operator or using an automated routine (for example vision-based place recognition method). The need for an accurate initial estimate is a severe drawback in the context of map-merging.

To be able to work without any initial estimate the algorithm presented in Chapter~\ref{chap:mergingalgorithm} uses a feature matching approach, that does not require any initial estimate and is not affected by the initial configuration of the maps. These feature-matching approaches use descriptors developed specifically for point clouds, such as \gls{PFH}, introduced by~\citet{rusu2008pfh}, to match keypoints between two maps. These algorithms have been developed for high-density point clouds produced directly by sensors such as laser range finder and \gls{RGB-D} cameras. Some of the proposed features, such as \gls{NARF} introduced by~\citet{steder2010narf}, use range image representation and a single viewpoint assumption, that cannot be generalised to \gls{3D} point cloud maps. I show that it is viable to use feature-matching also for registration of low-density point cloud when we take specifics of the point cloud maps into account.
